<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://norlab.ulaval.ca/atom.xml" rel="self" type="application/atom+xml" /><link href="https://norlab.ulaval.ca/" rel="alternate" type="text/html" /><updated>2019-03-04T22:32:23-05:00</updated><id>https://norlab.ulaval.ca/atom.xml</id><title type="html">Northern Robotics Laboratory</title><subtitle>Website showcasing research and news from the Northern Robotics Laboratory, Laval University</subtitle><entry><title type="html">Three articles accepted at ICRA 2019!</title><link href="https://norlab.ulaval.ca/news/icra19/" rel="alternate" type="text/html" title="Three articles accepted at ICRA 2019!" /><published>2019-03-04T00:00:00-05:00</published><updated>2019-03-04T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/news/icra19</id><content type="html" xml:base="https://norlab.ulaval.ca/news/icra19/">&lt;p&gt;We are happy to announce that we have three accepted publications at the &lt;a href=&quot;https://www.icra2019.org/&quot;&gt;2019 International Conference on Robotics and Automation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will present our latest results on lidar modeling &lt;a href=&quot;#Laconte2019&quot;&gt;(Laconte, Deschênes, Labussière, &amp;amp; Pomerleau, 2019)&lt;/a&gt;, learning algorithm for covariance estimation &lt;a href=&quot;#Landry2019&quot;&gt;(Landry, Pomerleau, &amp;amp; Giguère, 2019)&lt;/a&gt;, and a survey on different robust cost functions applied to ICP (Iterative Closest Point) &lt;a href=&quot;#Babin2019&quot;&gt;(Babin, Giguère, &amp;amp; Pomerleau, 2019)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;More details, and hopefully videos to come!&lt;/p&gt;

&lt;h1 id=&quot;our-articles&quot;&gt;Our articles&lt;/h1&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Laconte2019&quot;&gt;Laconte, J., Deschênes, S.-P., Labussière, M., &amp;amp; Pomerleau, F. (2019). Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Laconte2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Landry2019&quot;&gt;Landry, D., Pomerleau, F., &amp;amp; Giguère, P. (2019). CELLO-3D: Estimating the Covariance of ICP in the Real World. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Landry2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Babin2019&quot;&gt;Babin, P., Giguère, P., &amp;amp; Pomerleau, F. (2019). Analysis of Robust Functions for Registration Algorithms. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Babin2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="conference" /><summary type="html">We are happy to announce that we have three accepted publications at the 2019 International Conference on Robotics and Automation.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/news/icra19/icra19_teaser.jpg%22%7D" /></entry><entry><title type="html">Vladimír Kubelka</title><link href="https://norlab.ulaval.ca/people/v_kubelka/" rel="alternate" type="text/html" title="Vladimír Kubelka" /><published>2019-02-21T00:00:00-05:00</published><updated>2019-02-21T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/people/v_kubelka</id><content type="html" xml:base="https://norlab.ulaval.ca/people/v_kubelka/">&lt;p&gt;Vladimír has received his master’s degree in Cybernetics and Robotics from the Czech Technical University in Prague (2013). The experiments for the master’s thesis were performed at the ASL lab (ETH Zurich) during his visiting student internship. After that, he continued as a Ph.D. student at CTU and focused on the problem of data fusion and state estimation for ground robots in harsh conditions. He had the opportunity to participate in two EU-funded  search and rescue projects &lt;a href=&quot;http://www.nifti.eu/&quot; target=&quot;_blank&quot;&gt;NIFTi&lt;/a&gt; and &lt;a href=&quot;http://www.tradr-project.eu/&quot; target=&quot;_blank&quot;&gt;TRADR&lt;/a&gt;. These projects offered real-world scenarios to test the localization algorithms. The main challenge were sensor outages (because of dark areas, smoke), unstable terrain and semi-structured environments (e.g., earthquake aftermath). He defended his Ph.D. thesis in 2018 (supervised by &lt;a href=&quot;https://sites.google.com/site/reinsmic&quot; target=&quot;_blank&quot;&gt;Michal Reinstein&lt;/a&gt; and &lt;a href=&quot;http://cmp.felk.cvut.cz/~svoboda/&quot; target=&quot;_blank&quot;&gt;Tomáš Svoboda&lt;/a&gt;) and enrolled as a postdoc fellow with the NORLAB. The Canadian winter brings new challenges for the ground mobile robots: deep snow, adversary conditions for optical sensors and changing terrain caused by wind and blizzards.&lt;/p&gt;

&lt;p&gt;His research topics are sensor fusion and state estimation for mobile ground robots. He is interested in the problems related to deployment of robots in harsh environments.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/file/d/12CeiSDOmbEq74qiiiJG8GhfCNXyB24Cp/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Ph.D.&lt;/a&gt; in Artificial Intelligence and Biocybernetics - &lt;a href=&quot;https://www.cvut.cz/en&quot; target=&quot;_blank&quot;&gt;CTU in Prague&lt;/a&gt;, 2018&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/file/d/1kA04kmKFjoW7k5Jas_8xn0ivKFFsQRWb/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Ing.&lt;/a&gt; in Cybernetics and Robotics (Air and Space Systems) - &lt;a href=&quot;https://www.cvut.cz/en&quot; target=&quot;_blank&quot;&gt;CTU in Prague&lt;/a&gt;, 2013&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/file/d/18vtdAQDF4s1qFMwPujufjYuyXQ_VlfzI/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Bc.&lt;/a&gt; in Electrical Engineering (Cybernetics and Measurement) - &lt;a href=&quot;https://www.cvut.cz/en&quot; target=&quot;_blank&quot;&gt;CTU in Prague&lt;/a&gt;, 2011&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;h2 class=&quot;bibliography&quot;&gt;Journal Articles&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;kubelka2016improving&quot;&gt;Kubelka, V., Reinstein, M., &amp;amp; Svoboda, T. (2016). Improving multimodal data fusion for mobile robots by trajectory smoothing. &lt;i&gt;Robotics and Autonomous Systems&lt;/i&gt;, &lt;i&gt;84&lt;/i&gt;, 88–96.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kubelka2016improving/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Pomerleau2015e&quot;&gt;Kubelka, V., Oswald, L., Pomerleau, F., Colas, F., Svoboda, T., &amp;amp; Reinstein, M. (2015). Robust data fusion of multimodal sensory information for mobile robots. &lt;i&gt;Journal of Field Robotics&lt;/i&gt;, &lt;i&gt;32&lt;/i&gt;(4), 447–473.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Pomerleau2015e/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;simanek2015evaluation&quot;&gt;Simanek, J., Reinstein, M., &amp;amp; Kubelka, V. (2015). Evaluation of the EKF-based estimation architectures for data fusion in mobile robots. &lt;i&gt;IEEE/ASME Transactions on Mechatronics&lt;/i&gt;, &lt;i&gt;20&lt;/i&gt;(2), 985–990.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/simanek2015evaluation/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;simanek2015improving&quot;&gt;Simanek, J., Kubelka, V., &amp;amp; Reinstein, M. (2015). Improving multi-modal data fusion by anomaly detection. &lt;i&gt;Autonomous Robots&lt;/i&gt;, &lt;i&gt;39&lt;/i&gt;(2), 139–154.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/simanek2015improving/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;h2 class=&quot;bibliography&quot;&gt;Conference Articles&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;kruijff2016deployment&quot;&gt;Kruijff-Korbayová, I., Freda, L., Gianni, M., Ntouskos, V., Hlaváč, V., Kubelka, V., … others. (2016). Deployment of ground and aerial robots in earthquake-struck amatrice in italy (brief report). In &lt;i&gt;2016 IEEE international symposium on safety, security, and rescue robotics (SSRR)&lt;/i&gt; (pp. 278–279). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kruijff2016deployment/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;jirkuu2016wifi&quot;&gt;Jirku, M., Kubelka, V., &amp;amp; Reinstein, M. (2016). WiFi localization in 3D. In &lt;i&gt;2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)&lt;/i&gt; (pp. 4551–4557). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/jirkuu2016wifi/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;kubelka2014combining&quot;&gt;Kubelka, V., &amp;amp; Reinstein, M. (2014). Combining Complementary Motion Estimation Approaches to Increase Reliability in Urban Search &amp;amp; Rescue Missions. In &lt;i&gt;International Workshop on Modelling and Simulation for Autonomous Systems&lt;/i&gt; (pp. 347–356). Springer, Cham.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kubelka2014combining/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;reinstein2013terrain&quot;&gt;Reinstein, M., Kubelka, V., &amp;amp; Zimmermann, K. (2013). Terrain adaptive odometry for mobile skid-steer robots. In &lt;i&gt;2013 IEEE International Conference on Robotics and Automation&lt;/i&gt; (pp. 4706–4711). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/reinstein2013terrain/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;kubelka2012complementary&quot;&gt;Kubelka, V., &amp;amp; Reinstein, M. (2012). Complementary filtering approach to orientation estimation using inertial sensors only. In &lt;i&gt;2012 IEEE international conference on robotics and automation&lt;/i&gt; (pp. 599–605). IEEE.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/kubelka2012complementary/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Vladimír Kubelka</name><email>vladimir.kubelka.1@ulaval.ca</email></author><summary type="html">Vladimír has received his master’s degree in Cybernetics and Robotics from the Czech Technical University in Prague (2013). The experiments for the master’s thesis were performed at the ASL lab (ETH Zurich) during his visiting student internship. After that, he continued as a Ph.D. student at CTU and focused on the problem of data fusion and state estimation for ground robots in harsh conditions. He had the opportunity to participate in two EU-funded search and rescue projects NIFTi and TRADR. These projects offered real-world scenarios to test the localization algorithms. The main challenge were sensor outages (because of dark areas, smoke), unstable terrain and semi-structured environments (e.g., earthquake aftermath). He defended his Ph.D. thesis in 2018 (supervised by Michal Reinstein and Tomáš Svoboda) and enrolled as a postdoc fellow with the NORLAB. The Canadian winter brings new challenges for the ground mobile robots: deep snow, adversary conditions for optical sensors and changing terrain caused by wind and blizzards.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/v_kubelka.jpg%22,%20%22teaser%22=%3E%22/people/v_kubelka_avatar.jpg%22%7D" /></entry><entry><title type="html">Maxime Vaidis</title><link href="https://norlab.ulaval.ca/people/m_vaidis/" rel="alternate" type="text/html" title="Maxime Vaidis" /><published>2019-01-30T00:00:00-05:00</published><updated>2019-01-30T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/people/m_vaidis</id><content type="html" xml:base="https://norlab.ulaval.ca/people/m_vaidis/">&lt;p&gt;Maxime Vaidis is currently a Ph.D student in Norlab laboratory.
He got a formation in mathematics and physics of two years in the preparatory classes for the Grandes Ecoles at Faidherbe (Lille, France) as well as two Master’s degrees, one in electrical Engineering from UQAC (University of Quebec At Chicoutimi, Canada), and an other one in Telecommunication and computer Engineering from  Telecom Saint Etienne (University of Jean Monnet-Saint-Etienne, France).
He did an internship at UQAC in LAIMI laboratory (Automatic and 3D Multimodal Intelligent Interaction Laboratory), during which he participated in the develoment of a smart insole and a creation of a new type of robot’s swarm and his interaction which a human operator.
He also worked for ConformiT compagny through a research contrat to develop a new accident-prevention system working with some Deep learning.
His current works are about to develop a robot which can map some caves with Lidar sensors.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Master’s degree in electrical Engineering at UQAC (University of Quebec At Chicoutimi, Canada), 2016-2018&lt;/li&gt;
  &lt;li&gt;Master’s degree in Telecommunication and computer Engineering from  Telecom Saint Etienne (University of Jean Monnet-Saint-Etienne, France), 2014-2018&lt;/li&gt;
  &lt;li&gt;Preparatory classes for the Grandes Ecoles in Mathematics and Physics at Faidherbe (Lille, France), 2012-2014&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;</content><author><name>Maxime Vaidis</name><email>vaidis.maxime@gmail.com</email></author><summary type="html">Maxime Vaidis is currently a Ph.D student in Norlab laboratory. He got a formation in mathematics and physics of two years in the preparatory classes for the Grandes Ecoles at Faidherbe (Lille, France) as well as two Master’s degrees, one in electrical Engineering from UQAC (University of Quebec At Chicoutimi, Canada), and an other one in Telecommunication and computer Engineering from Telecom Saint Etienne (University of Jean Monnet-Saint-Etienne, France). He did an internship at UQAC in LAIMI laboratory (Automatic and 3D Multimodal Intelligent Interaction Laboratory), during which he participated in the develoment of a smart insole and a creation of a new type of robot’s swarm and his interaction which a human operator. He also worked for ConformiT compagny through a research contrat to develop a new accident-prevention system working with some Deep learning. His current works are about to develop a robot which can map some caves with Lidar sensors.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/m_vaidis.jpg%22,%20%22teaser%22=%3E%22/people/m_vaidis_avatar.jpg%22%7D" /></entry><entry><title type="html">Maxime Vaidis</title><link href="https://norlab.ulaval.ca/people/m_vaidis_fr/" rel="alternate" type="text/html" title="Maxime Vaidis" /><published>2019-01-30T00:00:00-05:00</published><updated>2019-01-30T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/people/m_vaidis_fr</id><content type="html" xml:base="https://norlab.ulaval.ca/people/m_vaidis_fr/">&lt;p&gt;Maxime Vaidis est actuellement un étudiant au doctorat au laboratoire Norlab.
Il a effectué une formation en mathématiques et physique de deux ans dans les Classes Préparatoire aux Grandes Écoles de Faidherbe (Lille, France). Il possède également deux diplômes de Master, l’un en Génie éléctrique obtenu à l’UQAC (Université du Québec à Chicoutimi, Canada) et l’autre en Télécommunication et Informatique obtenu à Télécom Saint Etienne (Université Jean Monnet-Saint-Etienne, France).
Il a effectué un stage à l’université de l’UQAC au laboratoire LAIMI (Laboratoire d’Automatisme et d’Intéractions 3D Multimodales) durant lequel il a participé au développement d’une semelle intelligente et à la création d’un nouveau type d’essaim de robots et de son intéraction avec l’opérateur humain.
Il a également travaillé pour l’entreprise ConformiT à travers un contrat de recherche visant à développer un système de prévention d’accident au travail utilsant le Deep Learning.
Son travail actuel est de développer un robot pouvant scanner et cartographier des grottes en utilisant des capteurs Lidar.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Diplôme de Master en Génie Éléctrique à l’UQAC (Université du Québec à Chicoutimi, Canada), 2016-2018&lt;/li&gt;
  &lt;li&gt;Diplôme de Master en Télécommunication et Informatique à Télécom Saint Etienne (Université Jean Monnet-Saint-Etienne, France), 2014-2018&lt;/li&gt;
  &lt;li&gt;Classes Préparatoire aux Grandes Écoles en Mathématiques et Physique à Faidherbe (Lille, France), 2012-2014&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;</content><author><name>Maxime Vaidis</name><email>vaidis.maxime@gmail.com</email></author><summary type="html">Maxime Vaidis est actuellement un étudiant au doctorat au laboratoire Norlab. Il a effectué une formation en mathématiques et physique de deux ans dans les Classes Préparatoire aux Grandes Écoles de Faidherbe (Lille, France). Il possède également deux diplômes de Master, l’un en Génie éléctrique obtenu à l’UQAC (Université du Québec à Chicoutimi, Canada) et l’autre en Télécommunication et Informatique obtenu à Télécom Saint Etienne (Université Jean Monnet-Saint-Etienne, France). Il a effectué un stage à l’université de l’UQAC au laboratoire LAIMI (Laboratoire d’Automatisme et d’Intéractions 3D Multimodales) durant lequel il a participé au développement d’une semelle intelligente et à la création d’un nouveau type d’essaim de robots et de son intéraction avec l’opérateur humain. Il a également travaillé pour l’entreprise ConformiT à travers un contrat de recherche visant à développer un système de prévention d’accident au travail utilsant le Deep Learning. Son travail actuel est de développer un robot pouvant scanner et cartographier des grottes en utilisant des capteurs Lidar.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/m_vaidis.jpg%22,%20%22teaser%22=%3E%22/people/m_vaidis_avatar.jpg%22%7D" /></entry><entry><title type="html">Information for Prospective Students</title><link href="https://norlab.ulaval.ca/research/prospective-students/" rel="alternate" type="text/html" title="Information for Prospective Students" /><published>2018-11-30T00:00:00-05:00</published><updated>2018-11-30T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/research/prospective-students</id><content type="html" xml:base="https://norlab.ulaval.ca/research/prospective-students/">&lt;p&gt;Here are some information for prospective students who want to apply to a position at Norlab.
Read those information carefully before communicating with us.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For international students&lt;/strong&gt;, because of the immigration procedure and the risk of recruiting with limited information, we will only answer emails which are recommended by a professor known by the laboratory.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For Canadian students&lt;/strong&gt;, it is expected that you will ask for funding to the &lt;a href=&quot;http://www.nserc-crsng.gc.ca/Students-Etudiants/PG-CS/index_eng.asp&quot;&gt;Natural Sciences and Engineering Research Council of Canada (NSERC)&lt;/a&gt;, and students from Quebec are expected to also ask for funding to the &lt;a href=&quot;http://www.frqnt.gouv.qc.ca/en/bourses-et-subventions&quot;&gt;Fonds de recherche du Québec Nature et technologies (FRQNT)&lt;/a&gt;.
It takes typically 8 months to receive and answer from the funding agencies, so you need to plan at least a year in advance if you want to do research in our lab.
If you have a high profile, we offer support to write a strong proposal. 
Those grants are highly competitive, so you will need to work on research skills, grads, and social implications through your undergraduate studies.&lt;/p&gt;

&lt;p&gt;We try to keep an international level of research, so are expectations might be higher than anticipated.
Here is a breakdown of workload and support from Norlab for each level of researcher:&lt;/p&gt;

&lt;div class=&quot;grid&quot;&gt;
&lt;div class=&quot;three-cols&quot;&gt;
    &lt;h1 class=&quot;col-title&quot;&gt; M. Sc. &lt;/h1&gt;
    &lt;p&gt;Workload:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Minimum 2 years&lt;/li&gt;
      &lt;li&gt;Minimum 1 publication&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#suggested-lectures&quot;&gt;3-4 lectures&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Support:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Grant of $17 000 / year&lt;/li&gt;
      &lt;li&gt;Bonus of $5 000 from Norlab if you have a grant from NSERC or FRQNT&lt;/li&gt;
      &lt;li&gt;A maximum of $650 in grants for merit&lt;/li&gt;
      &lt;li&gt;Travel expenses to &lt;a href=&quot;#targeted-journals-and-conferences&quot;&gt;international conferences&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/div&gt;

&lt;div class=&quot;three-cols&quot;&gt;
    &lt;h1 class=&quot;col-title&quot;&gt; Ph. D. &lt;/h1&gt;
    &lt;p&gt;Workload:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Minimum 3 years&lt;/li&gt;
      &lt;li&gt;Minimum 3 publications&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#suggested-lectures&quot;&gt;3 lectures&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Support:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Grant of $21 000 / year&lt;/li&gt;
      &lt;li&gt;Bonus of $8 000 from Norlab if you have a grant from NSERC or FRQNT&lt;/li&gt;
      &lt;li&gt;A total of $3 500 in grants for a regular progression&lt;/li&gt;
      &lt;li&gt;A maximum of $8 500 in grants for merit (including $750 / publication and $1000 / conference)&lt;/li&gt;
      &lt;li&gt;International students receive a tuition fee exemption&lt;/li&gt;
      &lt;li&gt;Possibility of 4-8 months training &lt;a href=&quot;#our-international-network&quot;&gt;abroad&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Travel expenses to &lt;a href=&quot;#targeted-journals-and-conferences&quot;&gt;international conferences&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

  &lt;/div&gt;

&lt;div class=&quot;three-cols&quot;&gt;
    &lt;h1 class=&quot;col-title&quot;&gt; Postdoc &lt;/h1&gt;
    &lt;p&gt;Workload:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Project management&lt;/li&gt;
      &lt;li&gt;Active publications&lt;/li&gt;
      &lt;li&gt;Student supervision&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Support:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Negotiable salary&lt;/li&gt;
      &lt;li&gt;Salary includes benefits such as pension and insurances&lt;/li&gt;
      &lt;li&gt;International postdoc can ask for a provincial tax exemption&lt;/li&gt;
      &lt;li&gt;Travel expenses to &lt;a href=&quot;#targeted-journals-and-conferences&quot;&gt;international conferences&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

  &lt;/div&gt;

&lt;/div&gt;
&lt;p&gt;&lt;!-- class=&quot;grid&quot;--&gt;&lt;/p&gt;

&lt;p&gt;… and for all levels, you should&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;be self-driven, autonomous, ethical, and meticulous&lt;/li&gt;
  &lt;li&gt;develop communication skills with international standards&lt;/li&gt;
  &lt;li&gt;have an active implication in the development and maintenance of lab’s  infrastructure&lt;/li&gt;
  &lt;li&gt;support teaching activities through paid contracts, when needed&lt;/li&gt;
  &lt;li&gt;demonstrate collegiality through social activities of the lab&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This information is given as an average and the specific details will depend on the status and particularities of each candidate.&lt;/p&gt;

&lt;h1 id=&quot;suggested-lectures&quot;&gt;Suggested Lectures&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Introduction to mobile robotics (GLO-7021)&lt;/li&gt;
  &lt;li&gt;Learning through deep neural networks (GLO-7030)&lt;/li&gt;
  &lt;li&gt;Advance techniques in artificial intelligence (IFT-7025)&lt;/li&gt;
  &lt;li&gt;Numerical vision (GIF-7001)&lt;/li&gt;
  &lt;li&gt;Algorithmic photography (GIF-7105)&lt;/li&gt;
  &lt;li&gt;Elements of robotics (GMC-7046)&lt;/li&gt;
  &lt;li&gt;Active sensors (GMT-7007)&lt;/li&gt;
  &lt;li&gt;Advanced satellite positioning (GMT-7037)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;targeted-journals-and-conferences&quot;&gt;Targeted Journals and Conferences&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;International Journal of Robotics Research&lt;/li&gt;
  &lt;li&gt;Journal of Field Robotics (JFR)&lt;/li&gt;
  &lt;li&gt;Autonomous Robots&lt;/li&gt;
  &lt;li&gt;IEEE Robotics and Automation Letters (RA-L)&lt;/li&gt;
  &lt;li&gt;IEEE International Conference on Robotics and Automation (ICRA) - location rotating through North America, Europe, and Asia each year.&lt;/li&gt;
  &lt;li&gt;IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) - location rotating through North America, Europe, and Asia each year.&lt;/li&gt;
  &lt;li&gt;International Conference on Field and Service Robotics (FSR) - location rotating through North America, Europe, and Asia each year.&lt;/li&gt;
  &lt;li&gt;International Conference on Robotics: Science and Systems (RSS) - typically in the US.&lt;/li&gt;
  &lt;li&gt;Conference on Computer and Robot Vision (CRV) - typically in Canada.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;our-international-network&quot;&gt;Our International Network&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Switzerland: ETH Zurich&lt;/li&gt;
  &lt;li&gt;Hong Kong: Hong Kong University of Science and Technology&lt;/li&gt;
  &lt;li&gt;China: ShanghaiTech&lt;/li&gt;
  &lt;li&gt;England: Oxford&lt;/li&gt;
  &lt;li&gt;Australia: Queensland University of Technology’s (QUT)&lt;/li&gt;
  &lt;li&gt;Germany: University of Bonn&lt;/li&gt;
  &lt;li&gt;France: Georgia Tech Lorraine; Institut Pascal&lt;/li&gt;
  &lt;li&gt;USA: Jet Propulsion Laboratory; University of Nevada&lt;/li&gt;
  &lt;li&gt;Canada: University of Toronto; McGill&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;how-to-apply&quot;&gt;How to apply&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;Read about grant opportunities from &lt;a href=&quot;http://www.nserc-crsng.gc.ca/Students-Etudiants/PG-CS/index_eng.asp&quot;&gt;NSERC&lt;/a&gt; and &lt;a href=&quot;http://www.frqnt.gouv.qc.ca/en/bourses-et-subventions&quot;&gt;FRQNT&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Read about the &lt;a href=&quot;/research/#projects&quot;&gt;past and current projects&lt;/a&gt; to make sure that the general topic highly motivate you&lt;/li&gt;
  &lt;li&gt;Read about graduated studies on the &lt;a href=&quot;https://www.fesp.ulaval.ca/&quot;&gt;Faculty of graduated and postdoctoral studies&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Make sure that we are advertising an open position on our web site, then…&lt;/li&gt;
  &lt;li&gt;Contact us for a meeting by mentioning a specific project.&lt;/li&gt;
&lt;/ol&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="howto" /><category term="grants" /><category term="salary" /><category term="students" /><summary type="html">Here are some information for prospective students who want to apply to a position at Norlab. Read those information carefully before communicating with us.</summary></entry><entry><title type="html">Manipulation</title><link href="https://norlab.ulaval.ca/research/manipulation/" rel="alternate" type="text/html" title="Manipulation" /><published>2018-11-23T00:00:00-05:00</published><updated>2018-11-23T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/research/manipulation</id><content type="html" xml:base="https://norlab.ulaval.ca/research/manipulation/">&lt;p style=&quot;text-align: center;&quot;&gt;
	&lt;a class=&quot;btn-info&quot; href=&quot;/research/prospective-students&quot;&gt;Open position for a Ph.D. student!&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;This project is financed through &lt;a href=&quot;http://www.chistera.eu&quot;&gt;CHIST-ERA&lt;/a&gt; and is part of an international research project named &lt;em&gt;Perception-guided robust and reproducible robotic grasping and manipulation&lt;/em&gt;.
In this project, the team of researchers will address the problem of autonomous robotic grasping of objects in challenging scenes.&lt;/p&gt;

&lt;p&gt;We consider two industrially and economically important open challenges which require advanced vision-guided grasping:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;“Bin-picking” for manufacturing, where components must be grasped from a random, self-occluding heap inside a bin or box. 
Parts may have known models, but will only be partially visible in the heap and may have complex shapes. 
Shiny/reflective metal parts make 3D vision difficult, and the bin walls provide difficult reach-to-grasp and visibility constraints.&lt;/li&gt;
  &lt;li&gt;Waste materials handling, which may be hazardous (e.g., nuclear) waste, or materials for recycling in the circular economy. 
Here the robot has no prior models of object shapes, and grasped materials may also be deformable (e.g., contaminated gloves, hoses).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;More specifically, Norlab will be responsible to investigate 3D perception solutions robust to harsh environmental conditions leading to the grasping of reflective, transparent, or flexible objects.
The initial solutions will be proposed using an UR10e equipped with a flash lidar on the wrist.&lt;/p&gt;

&lt;h1 id=&quot;team&quot;&gt;Team&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Principal Investigator&lt;/strong&gt;: &lt;a href=&quot;https://robot.gmc.ulaval.ca/en/members/current-members/clement-gosselin/&quot;&gt;Clément Gosselin&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PI on Perception&lt;/strong&gt;: &lt;a href=&quot;../../people/f_pomerleau/&quot;&gt;François Pomerleau&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;International Collaborators&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Italy: &lt;a href=&quot;http://www.centropiaggio.unipi.it/~bicchi&quot;&gt;Antonio Bicchi&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;United Kingdom: &lt;a href=&quot;https://www.birmingham.ac.uk/staff/profiles/metallurgy/stolkin-rustam.aspx&quot;&gt;Rustam Stolkin&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Technical Lead&lt;/strong&gt;: TBD&lt;/li&gt;
&lt;/ul&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="project" /><category term="mapping" /><category term="robot. arm" /><category term="gripper" /><category term="flash lidar" /><summary type="html">Open position for a Ph.D. student!</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22projects/manipulation_feature.jpg%22,%20%22teaser%22=%3E%22projects/manipulation_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry><entry><title type="html">Johann Laconte</title><link href="https://norlab.ulaval.ca/people/j_laconte/" rel="alternate" type="text/html" title="Johann Laconte" /><published>2018-11-22T00:00:00-05:00</published><updated>2018-11-22T00:00:00-05:00</updated><id>https://norlab.ulaval.ca/people/j_laconte</id><content type="html" xml:base="https://norlab.ulaval.ca/people/j_laconte/">&lt;p&gt;Johann Laconte is currently a Ph.D student in robotics at Institut Pascal, France. 
He got an Engineering degree in computer sciences and modelisation from ISIMA (Institut Supérieur d’Informatique, de Modélisation et de leurs Applications) as well as a Master’s degree in Robotics from Université d’Auvergne, France, in 2018.
He did an internship at Thales, during which he participated in the development of LIDAR SLAM algorithm.
He also did an research internship at Norlab, working on the characterization of LIDAR’s bias.
His current works are about traversability and risk assessments in dynamic environments.&lt;/p&gt;

&lt;h1 id=&quot;education&quot;&gt;Education&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;M.Sc. in Robotics and Artificial Perception - University of Auvergne (UCA), 2018&lt;/li&gt;
  &lt;li&gt;Engineering degree in computer Sciences and Modelisation - Institut Supérieur d’Informatique, de Modélisation et de leurs Applications (ISIMA), 2018&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;publications&quot;&gt;Publications&lt;/h1&gt;

&lt;h2 class=&quot;bibliography&quot;&gt;Conference Articles&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Labussiere2019&quot;&gt;Labussière, M., Laconte, J., &amp;amp; Pomerleau, F. (2019). Geometry Preserving Sampling Method based on Spectral Decomposition for 3D Registration. In &lt;i&gt;preprint, arXiv&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Labussiere2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Laconte2019&quot;&gt;Laconte, J., Deschênes, S.-P., Labussière, M., &amp;amp; Pomerleau, F. (2019). Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Laconte2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Johann Laconte</name></author><summary type="html">Johann Laconte is currently a Ph.D student in robotics at Institut Pascal, France. He got an Engineering degree in computer sciences and modelisation from ISIMA (Institut Supérieur d’Informatique, de Modélisation et de leurs Applications) as well as a Master’s degree in Robotics from Université d’Auvergne, France, in 2018. He did an internship at Thales, during which he participated in the development of LIDAR SLAM algorithm. He also did an research internship at Norlab, working on the characterization of LIDAR’s bias. His current works are about traversability and risk assessments in dynamic environments.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/people/j_laconte.jpg%22,%20%22teaser%22=%3E%22/people/j_laconte_avatar.jpg%22%7D" /></entry><entry><title type="html">First sensor from RoboSense in Quebec!</title><link href="https://norlab.ulaval.ca/news/new-sensor-robosense/" rel="alternate" type="text/html" title="First sensor from RoboSense in Quebec!" /><published>2018-10-26T00:00:00-04:00</published><updated>2018-10-26T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/news/new-sensor-robosense</id><content type="html" xml:base="https://norlab.ulaval.ca/news/new-sensor-robosense/">&lt;p&gt;The laboratory received recently a RS-LIDAR-16 from &lt;a href=&quot;http://robosense.ai&quot;&gt;RoboSense&lt;/a&gt;.
This is the first unit delivered in Quebec and we are happy to use it for our project on &lt;a href=&quot;/research/libpointmatcher/&quot;&gt;3D mapping&lt;/a&gt; and sensor characteristic identification.&lt;/p&gt;

&lt;p&gt;Our preliminary work with the RS-LIDAR-16 can be found on &lt;a href=&quot;https://arxiv.org/abs/1810.01619&quot;&gt;arXiv&lt;/a&gt; or &lt;a href=&quot;https://www.researchgate.net/publication/328063232_Lidar_Measurement_Bias_Estimation_via_Return_Waveform_Modelling_in_a_Context_of_3D_Mapping&quot;&gt;ResearchGate&lt;/a&gt; and has the following abstract:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&quot;In a context of 3D mapping, it is very important to get accurate measurements from sensors. In particular, Light Detection And Ranging (LIDAR) measurements are typically treated as a zero-mean Gaussian distribution. We show that this assumption leads to predictable localisation drifts, especially when a bias related to measuring obstacles with high incidence angles is not taken into consideration. Moreover, we present a way to physically understand and model this bias, which generalises to multiple sensors. Using an experimental setup, we measured the bias of the Sick LMS151, Velodyne HDL-32E, and Robosense RS-LiDAR-16 as a function of depth and incidence angle, and showed that the bias can go up to 20 cm for high incidence angles. We then used our modelisations to remove the bias from the measurements, leading to more accurate maps and a reduced localisation drift.&quot;&lt;/p&gt;&lt;cite&gt;&lt;a href=&quot;#Laconte2019&quot;&gt;(Laconte, Deschênes, Labussière, &amp;amp; Pomerleau, 2019)&lt;/a&gt;&lt;/cite&gt;&lt;/blockquote&gt;

&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;span id=&quot;Laconte2019&quot;&gt;Laconte, J., Deschênes, S.-P., Labussière, M., &amp;amp; Pomerleau, F. (2019). Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping. In &lt;i&gt;Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)&lt;/i&gt;.&lt;/span&gt;&lt;a class=&quot;details&quot; href=&quot;/bibliography/Laconte2019/&quot;&gt; Bibtex source&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="sensors" /><category term="industry" /><summary type="html">The laboratory received recently a RS-LIDAR-16 from RoboSense. This is the first unit delivered in Quebec and we are happy to use it for our project on 3D mapping and sensor characteristic identification.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22/news/robosense/robosenseRS16_feature.jpg%22,%20%22teaser%22=%3E%22/news/robosense/robosenseRS16_teaser.jpg%22%7D" /></entry><entry><title type="html">How to comment a ROS launch file</title><link href="https://norlab.ulaval.ca/research/how-to-comment-lauch-file/" rel="alternate" type="text/html" title="How to comment a ROS launch file" /><published>2018-05-16T00:00:00-04:00</published><updated>2018-05-16T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/research/how-to-comment-lauch-file</id><content type="html" xml:base="https://norlab.ulaval.ca/research/how-to-comment-lauch-file/">&lt;p&gt;I am always forgetting how to have a nested comments in a &lt;a href=&quot;http://wiki.ros.org/roslaunch/XML&quot;&gt;ROS launch file&lt;/a&gt;, so I’m putting this information here in the hope to reduce my time searching on Google.&lt;/p&gt;

&lt;h1 id=&quot;the-problem&quot;&gt;The Problem&lt;/h1&gt;

&lt;p&gt;I often have a large launch file with multiple comments in it so I can recall what each parameter do.
Here is the file that was causing me some troubles:&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;&amp;lt;!--
This launch file is an example for 3D registration using DSO stero reconstruction

--&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;launch&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;node&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mapper&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dynamic_mapper&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;pkg=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ethzasl_icp_mapper&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;output=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;screen&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;remap&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;from=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cloud_in&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;to=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/csv_to_pc2/pointcloud&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;subscribe_scan&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;false&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;subscribe_cloud&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;icpConfig&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$(find ethzasl_icp_mapper)/launch/kingfisher/DSO/icp.yaml&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;inputFiltersConfig&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$(find ethzasl_icp_mapper)/launch/kingfisher/DSO/input_filters.yaml&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mapPostFiltersConfig&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$(find ethzasl_icp_mapper)/launch/kingfisher/DSO/map_post_filters.yaml&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;odom_frame&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/pointcloud&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;map_frame&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/map&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;useROSLogger&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;minOverlap&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.1&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt; 
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;maxOverlapToMerge&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.85&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt; 
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;minMapPointCount&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;500&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt; 
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;minReadingPointCount&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;30&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt; 

		&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- Parameters for dynamic elements --&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;priorStatic&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.45&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;priorDyn&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.55&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;maxAngle&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.1&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;eps_a&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.004&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;&amp;lt;!--1 deg = 0.017rad--&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;eps_d&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.005&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;alpha&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.99&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;beta&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.90&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;maxDyn&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.90&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;

		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;maxDistNewPoint&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.1&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sensorMaxRange&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;20.0&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;


	&lt;span class=&quot;nt&quot;&gt;&amp;lt;/node&amp;gt;&lt;/span&gt;

	&lt;span class=&quot;nt&quot;&gt;&amp;lt;node&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;pkg=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tf&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;static_transform_publisher&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;correction_tf&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;args=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0 0 0 0 0.2 0 /pointcloud /boat_level 100&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;/launch&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If I want to comment the node &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;node name=&quot;mapper&quot;&amp;gt;&lt;/code&gt;, the typical block comment &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;!-- --&amp;gt;&lt;/code&gt; will break because of the nested comment &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;!--1 deg = 0.017rad--&amp;gt;&lt;/code&gt;.
So much, that even the syntax highlight used for this web site will not render it properly:&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;launch&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;&amp;lt;!--node name=&quot;mapper&quot; type=&quot;dynamic_mapper&quot; pkg=&quot;ethzasl_icp_mapper&quot; output=&quot;screen&quot;&amp;gt;
		&amp;lt;param name=&quot;eps_a&quot; value=&quot;0.004&quot;/&amp;gt;&amp;lt;!--1 deg = 0.017rad--&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;/node--&amp;gt;&lt;/span&gt;

	&lt;span class=&quot;nt&quot;&gt;&amp;lt;node&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;pkg=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tf&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;static_transform_publisher&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;correction_tf&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;args=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0 0 0 0 0.2 0 /pointcloud /boat_level 100&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;/launch&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;solution&quot;&gt;Solution&lt;/h1&gt;

&lt;p&gt;Using the non-existing processing-instruction &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;?ignore &amp;lt;stuff&amp;gt; ?&amp;gt;&lt;/code&gt; will solve the problem and all the tags in between won’t be parsed and only the node &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;tf&amp;gt;&lt;/code&gt; will start:&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;launch&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;err&quot;&gt;&amp;lt;&lt;/span&gt;?ignore
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;node&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mapper&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dynamic_mapper&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;pkg=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ethzasl_icp_mapper&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;output=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;screen&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;param&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;eps_a&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.004&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;&amp;lt;!--1 deg = 0.017rad--&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;/node&amp;gt;&lt;/span&gt;
	?&amp;gt;

	&lt;span class=&quot;nt&quot;&gt;&amp;lt;node&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;pkg=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tf&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;static_transform_publisher&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;correction_tf&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;args=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0 0 0 0 0.2 0 /pointcloud /boat_level 100&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/launch&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="howto" /><category term="ros" /><category term="launch" /><category term="xml" /><summary type="html">I am always forgetting how to have a nested comments in a ROS launch file, so I’m putting this information here in the hope to reduce my time searching on Google.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22teaser%22=%3E%22/logos/ros_logo.svg%22,%20%22feature%22=%3E%22/logos/ros_logo.svg%22%7D" /></entry><entry><title type="html">Learning a Bias Correction for Lidar-only Motion Estimation</title><link href="https://norlab.ulaval.ca/publications/learning-bias/" rel="alternate" type="text/html" title="Learning a Bias Correction for Lidar-only Motion Estimation" /><published>2018-05-12T00:00:00-04:00</published><updated>2018-05-12T00:00:00-04:00</updated><id>https://norlab.ulaval.ca/publications/learning-bias</id><content type="html" xml:base="https://norlab.ulaval.ca/publications/learning-bias/">&lt;p&gt;This paper presents a novel technique to correct for bias in a classical estimator using a learning approach.
We apply a learned bias correction to a lidar-only motion estimation pipeline. Our technique trains a Gaussian process (GP) regression model using data with ground truth. 
The inputs to the model are high-level features derived from the geometry of the point-clouds, and the outputs are the predicted biases between poses computed by the estimator and the ground truth.
The predicted biases are applied as a correction to the poses computed by the estimator.
Our technique is evaluated on over 50 km of lidar data, including the KITTI odometry benchmark and lidar datasets collected around the University of Toronto campus. 
After applying the learned bias correction, we obtained significant improvements to lidar odometry in all datasets tested. 
We achieved around 10 % reduction in errors on all datasets from an already accurate lidar odometry algorithm, at the expense of only less than 1 % increase in computational cost at run-time.&lt;/p&gt;

&lt;h1 id=&quot;contributions&quot;&gt;Contributions&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Introduction of a novel technique to directly correct for the output of a classical state estimator using a learned bias correction&lt;/li&gt;
  &lt;li&gt;Demonstration of how scene geometry can be used to model biases in motion estimation&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;results-in-images&quot;&gt;Results in Images&lt;/h1&gt;

&lt;p&gt;If you’re curious about what those images represent, then you should read the full paper.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/publications/learning-bias/george4_before_captioned.jpg&quot; style=&quot;width: 100%&quot; /&gt;
&lt;img src=&quot;/images/publications/learning-bias/george4_after_captioned.jpg&quot; style=&quot;width: 100%&quot; /&gt;
&lt;img src=&quot;/images/publications/learning-bias/before_after.jpg&quot; style=&quot;width: 100%&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;span id=&quot;Pomerleau2018crv&quot;&gt;Tang, T., Yoon, D., Pomerleau, F., &amp;amp; Barfoot, T. D. (2018). Learning a Bias Correction for Lidar-Only Motion Estimation. In &lt;i&gt;Proceedings of the 15th Conference on Computer and Robot Vision (CRV)&lt;/i&gt;.&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&quot;links&quot;&gt;Links&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1801.04678&quot;&gt;Download link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>François Pomerleau</name><email>francois.pomerleau@ift.ulaval.ca</email></author><category term="publications" /><category term="ICP" /><category term="registration" /><category term="mapping" /><category term="robot" /><category term="localization" /><summary type="html">This paper presents a novel technique to correct for bias in a classical estimator using a learning approach. We apply a learned bias correction to a lidar-only motion estimation pipeline. Our technique trains a Gaussian process (GP) regression model using data with ground truth. The inputs to the model are high-level features derived from the geometry of the point-clouds, and the outputs are the predicted biases between poses computed by the estimator and the ground truth. The predicted biases are applied as a correction to the poses computed by the estimator. Our technique is evaluated on over 50 km of lidar data, including the KITTI odometry benchmark and lidar datasets collected around the University of Toronto campus. After applying the learned bias correction, we obtained significant improvements to lidar odometry in all datasets tested. We achieved around 10 % reduction in errors on all datasets from an already accurate lidar odometry algorithm, at the expense of only less than 1 % increase in computational cost at run-time.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://norlab.ulaval.ca/%7B%22feature%22=%3E%22publications/learning-bias_feature.jpg%22,%20%22teaser%22=%3E%22publications/learning-bias_teaser.jpg%22,%20%22thumb%22=%3Enil%7D" /></entry></feed>